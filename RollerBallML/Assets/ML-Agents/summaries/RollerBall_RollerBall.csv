Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,7.121654501216545,0.070490256,-0.7406718061282129,-0.7406718061282129,1.0
20000,1.4197353,8.396048918156161,-0.20782459,-0.688831764168309,-0.688831764168309,1.0
30000,1.4161694,9.364766839378238,-0.37065852,-0.6553343657874666,-0.6553343657874666,1.0
40000,1.4115149,10.457044673539519,-0.45887175,-0.4125062975550299,-0.4125062975550299,1.0
50000,1.4071869,10.787485242030696,-0.42693052,-0.2537110821818406,-0.2537110821818406,1.0
60000,1.4026906,11.680608365019012,-0.32219318,0.045349813166755536,0.045349813166755536,1.0
70000,1.3985891,11.699238578680204,-0.17643163,0.30977001532514636,0.30977001532514636,1.0
80000,1.3934796,11.759897828863346,-0.04044492,0.4397793400804607,0.4397793400804607,1.0
90000,1.388284,11.27027027027027,0.102616645,0.5960871205282358,0.5960871205282358,1.0
100000,1.3841189,11.484394506866417,0.23232332,0.7088664205426283,0.7088664205426283,1.0
110000,1.3810595,10.373863636363636,0.35341066,0.7828159133903683,0.7828159133903683,1.0
120000,1.3780695,9.80972972972973,0.46095926,0.7912648686283343,0.7912648686283343,1.0
130000,1.3750058,8.91765873015873,0.58140475,0.890004960349341,0.890004960349341,1.0
140000,1.3724984,8.832023575638507,0.66767025,0.8890088455264835,0.8890088455264835,1.0
150000,1.3706819,8.86771964461994,0.73095334,0.9121549902640114,0.9121549902640114,1.0
160000,1.3692976,8.344246959775491,0.76267284,0.918679144473919,0.918679144473919,1.0
170000,1.3681496,8.254865616311399,0.77473825,0.9361861153333275,0.9361861153333275,1.0
180000,1.3672993,8.132541133455211,0.77949804,0.9242931557028261,0.9242931557028261,1.0
190000,1.3668274,7.827890556045896,0.79128915,0.9533345148506569,0.9533345148506569,1.0
200000,1.3666239,7.758983347940403,0.80006564,0.962475485277677,0.962475485277677,1.0
